{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynndescent\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting scikit-learn>=0.18 (from pynndescent)\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy>=1.0 (from pynndescent)\n",
      "  Using cached scipy-1.15.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting numba>=0.51.2 (from pynndescent)\n",
      "  Using cached numba-0.61.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite>=0.30 (from pynndescent)\n",
      "  Using cached llvmlite-0.44.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting joblib>=0.11 (from pynndescent)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy<2.2,>=1.24 (from numba>=0.51.2->pynndescent)\n",
      "  Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.18->pynndescent)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached llvmlite-0.44.0-cp312-cp312-win_amd64.whl (30.3 MB)\n",
      "Using cached numba-0.61.0-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.1-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, llvmlite, joblib, scipy, numba, scikit-learn, pynndescent\n",
      "Successfully installed joblib-1.4.2 llvmlite-0.44.0 numba-0.61.0 numpy-2.1.3 pynndescent-0.5.13 scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE:\n",
    "Before running this, create a virtual environment running\n",
    "Python 3.12\n",
    "\"\"\" \n",
    "\n",
    "%pip install pynndescent\n",
    "%pip install torch \n",
    "%pip install transformers\n",
    "%pip install sentence-transformers\n",
    "%pip install pandas\n",
    "%pip install chonkie\n",
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 2.1 or less. Got NumPy 2.2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpynndescent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Add the current directory to the path\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "File \u001b[1;32mc:\\Users\\Steven\\Documents\\Python\\super-search\\.venv\\Lib\\site-packages\\pynndescent\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumba\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpynndescent_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NNDescent, PyNNDescentTransformer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Steven\\Documents\\Python\\super-search\\.venv\\Lib\\site-packages\\numba\\__init__.py:59\u001b[0m\n\u001b[0;32m     54\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m---> 59\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "File \u001b[1;32mc:\\Users\\Steven\\Documents\\Python\\super-search\\.venv\\Lib\\site-packages\\numba\\__init__.py:45\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     43\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 2.1 or less. Got NumPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Numba needs NumPy 2.1 or less. Got NumPy 2.2."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import StaticEmbedding\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pynndescent as nn\n",
    "\n",
    "# Add the current directory to the path\n",
    "sys.path.append(os.getcwd())\n",
    "from preprocess_fast_pymupdf import prepare_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "main = r\"C:\\Users\\Steven\\Documents\\Python\\super-search\"\n",
    "data = f\"{main}/data/tests\"\n",
    "test_file = f\"{data}/32286.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nPROMOTING PUBLIC HE...</td>\n",
       "      <td>PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32286\\nMarch 2024\\nJEL No. H70,I1,I11,J20\\nABS...</td>\n",
       "      <td>32286 March 2024 JEL No. H70,I1,I11,J20 study ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drawn to healthcare, relaxing shortages. On th...</td>\n",
       "      <td>drawn to healthcare, relaxing shortages. On ot...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and out of the industry. Our findings suggest ...</td>\n",
       "      <td>and out industry. findings suggest vaccine man...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Findings \\nsuggest trade-offs faced by health ...</td>\n",
       "      <td>Findings suggest trade-offs faced health polic...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>vertical lines.\\n55\\n Table A1: Healthcare ind...</td>\n",
       "      <td>vertical lines. 55 Table A1 Healthcare industr...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>(Flood et al., 2023).\\n56\\n Table A2: Healthca...</td>\n",
       "      <td>(Flood et al., 2023). 56 Table A2 Healthcare O...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>and ophthalmic medical technician\\nall other\\n...</td>\n",
       "      <td>and ophthalmic medical technician all other 35...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Population Survey. We use the variable OCC inc...</td>\n",
       "      <td>Population Survey. use variable OCC included i...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>current\\nemployment status, ages 21-64, with a...</td>\n",
       "      <td>current employment status, ages 21-64, additio...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_chunk  \\\n",
       "0    NBER WORKING PAPER SERIES\\nPROMOTING PUBLIC HE...   \n",
       "1    32286\\nMarch 2024\\nJEL No. H70,I1,I11,J20\\nABS...   \n",
       "2    drawn to healthcare, relaxing shortages. On th...   \n",
       "3    and out of the industry. Our findings suggest ...   \n",
       "4    Findings \\nsuggest trade-offs faced by health ...   \n",
       "..                                                 ...   \n",
       "242  vertical lines.\\n55\\n Table A1: Healthcare ind...   \n",
       "243  (Flood et al., 2023).\\n56\\n Table A2: Healthca...   \n",
       "244  and ophthalmic medical technician\\nall other\\n...   \n",
       "245  Population Survey. We use the variable OCC inc...   \n",
       "246  current\\nemployment status, ages 21-64, with a...   \n",
       "\n",
       "                                       processed_chunk  \\\n",
       "0    PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS...   \n",
       "1    32286 March 2024 JEL No. H70,I1,I11,J20 study ...   \n",
       "2    drawn to healthcare, relaxing shortages. On ot...   \n",
       "3    and out industry. findings suggest vaccine man...   \n",
       "4    Findings suggest trade-offs faced health polic...   \n",
       "..                                                 ...   \n",
       "242  vertical lines. 55 Table A1 Healthcare industr...   \n",
       "243  (Flood et al., 2023). 56 Table A2 Healthcare O...   \n",
       "244  and ophthalmic medical technician all other 35...   \n",
       "245  Population Survey. use variable OCC included i...   \n",
       "246  current employment status, ages 21-64, additio...   \n",
       "\n",
       "                                             file_path  \n",
       "0    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "1    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "2    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "3    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "4    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "..                                                 ...  \n",
       "242  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "243  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "244  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "245  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "246  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "\n",
       "[247 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(prepare_PDF(test_file))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS EVIDENCE FROM VACCINE MANDATES Rahi Abouk John S. Earle Johanna Catherine Maclean Sungbin Park Working Paper 32286 http //www.nber.org/papers/w32286 1050 Massachusetts Avenue Cambridge, MA 02138 March 2024 Research reported in publication supported National Institute on Mental Health National Institutes Health under Award Number 1R01MH132552 (PI Johanna Catherine Maclean). John Earle also acknowledges support Russell Sage Foundation. views expressed herein authors not necessarily reflect views National Institutes Health or. NBER working papers circulated discussion comment purposes. not peer-reviewed or subject to review NBER Board Directors accompanies official NBER publications. 2024 Rahi Abouk, John S. Earle, Johanna Catherine Maclean, Sungbin Park. All rights reserved. Short sections text, not to exceed two paragraphs, may quoted without explicit permission provided full credit, including notice, given to source. Promoting Public Health Blunt Instruments Evidence Vaccine Mandates Rahi Abouk, John S. Earle, Johanna Catherine Maclean, Sungbin Park NBER Working Paper No. 32286 March 2024 JEL No. H70,I1,I11,J20 study effect mandates requiring COVID-19 vaccination among healthcare industry workers adopted in 2021 in United States. There long-standing worker shortages in U.S. healthcare industry, pre-dating COVID-19 pandemic. impact COVID-19 vaccine mandates on shortages ex ante ambiguous. If mandates increase perceived safety healthcare industry, marginal workers may'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_PDF(test_file)['processed_chunk'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do:\n",
    "\n",
    "### Database management\n",
    "- We need a system to handle vector database as well as allowing for fast retrieval of the files corresponding to each vector\n",
    "    - Each file needs a file_id\n",
    "        - Links to the filepath\n",
    "    - Each chunk needs a chunk_id\n",
    "        - Links to the chunk text\n",
    "            - ~~Importantly, link to the original text, not the processed text used for embedding.~~\n",
    "                - ~~**I think the solution is to do the sentence chunking on the original text, before processing**~~\n",
    "    - file_id + chunk_id should uniquely identify a vector in the database\n",
    "- After taking a user query and encoding it, perform similarity search in the database\n",
    "    to identify a row, then link to the row's filepath and text\n",
    "- Then print a hyperlink to the file, and print the original text\n",
    "- **Problem**: how to return images, given that we first caption them with an LLM and then encode the caption?\n",
    "    - Also, should we treat each image description as a chunk, or subchunk the images for more accuracy?\n",
    "\n",
    "### Misc.\n",
    "- Parallelized PDF processing\n",
    "- Timing everything to understand where the bottlenecks are\n",
    "- Save performance statistics to report in the app\n",
    "    - How many PDF pages have been read? \n",
    "- ~~Switch to PyMuPDF~~ (It's much faster!!!)\n",
    "\n",
    "### Incorporating Images\n",
    "- Use PyMuPDF to extract images from each page of the PDF.\n",
    "- Goal is to pass each image to a multi-modal LLM for summary, which is then fed into the cleaned text.\n",
    "    - Possibly LLaVA for describing the images.\n",
    "    - Since captioning the images would take a super long time, this should be an optional step.\n",
    "        - Ideally would be done after first parsing the text, but then you might have to regenerate the whole vector base\n",
    "- **Why not just use an image encoder directly (if available)? Is it bad to mix embeddings from different encoders? probably**\n",
    "\n",
    "### GUI\n",
    "- The following should be customizable inputs:\n",
    "    - Chunk token size (\"larger is faster but less accurate\") (default: 256)\n",
    "    - Chunk overlap (\"larger gives more context per chunk\") (default: chunk_size / 4)\n",
    "    - Choice of sentence transformer: provide a few options based on speed/accuracy tradeoff.\n",
    "        - Fastest: static-retrieval-mrl-en-v1\n",
    "        - Medium: bge-m3\n",
    "        - Slowest: gte-large-en-v1.5\n",
    "        - (these are subject to change)\n",
    "    - Index database save location\n",
    "    - Similarity matrix (default: cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current encoding model implementation: static-retrieval-mrl-en-v1\n",
    "# https://huggingface.co/sentence-transformers/static-retrieval-mrl-en-v1\n",
    "# Model defaults to 1024 dense dimensions, but can be truncated to save space/time\n",
    "\n",
    "truncated_dimensions = 1024\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/static-retrieval-mrl-en-v1\"\n",
    "    , device=\"cpu\"\n",
    "    , truncate_dim=truncated_dimensions\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished filed 5.\n",
      "Finished filed 10.\n",
      "Finished filed 15.\n",
      "Finished filed 20.\n",
      "Finished filed 25.\n",
      "Finished filed 30.\n",
      "Finished filed 35.\n",
      "Finished filed 40.\n",
      "Finished filed 45.\n",
      "Finished filed 50.\n",
      "Finished filed 55.\n",
      "Finished filed 60.\n",
      "Finished filed 65.\n",
      "Finished filed 70.\n",
      "Finished filed 75.\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "Finished filed 80.\n",
      "Finished filed 85.\n",
      "Finished filed 90.\n",
      "Finished filed 95.\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "Finished filed 100.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...</td>\n",
       "      <td>RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>retirement ages. In this paper we find that th...</td>\n",
       "      <td>retirement ages. In paper find absence age-rel...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...</td>\n",
       "      <td>NBER lfriedberg virginia.edu Anthony Webb Inte...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1983 to 44% in 1998.1  \\nPension wealth in ...</td>\n",
       "      <td>in 1983 to 44% in 1998.1 Pension wealth in tra...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>early on in order to gain access to \\nlarge fu...</td>\n",
       "      <td>early on in order to gain access to large futu...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>effects (as percentage of steady state consump...</td>\n",
       "      <td>effects (as percentage steady state consumptio...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...</td>\n",
       "      <td>The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>\\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...</td>\n",
       "      <td>1.04 0.00 0.02 0.01  Stochastic steady state d...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19617</th>\n",
       "      <td>\\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...</td>\n",
       "      <td>-0.086 -0.081 capital stock (foreign) 0.431 0....</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>\\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....</td>\n",
       "      <td>u-overall (foreign) -0.751 -0.416 -0.491 -0.46...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19619 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_chunk  \\\n",
       "0      NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...   \n",
       "1      retirement ages. In this paper we find that th...   \n",
       "2      NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...   \n",
       "3      in 1983 to 44% in 1998.1  \\nPension wealth in ...   \n",
       "4      early on in order to gain access to \\nlarge fu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage of steady state consump...   \n",
       "19615  The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...   \n",
       "19616  \\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...   \n",
       "19617  \\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...   \n",
       "19618  \\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....   \n",
       "\n",
       "                                         processed_chunk  \\\n",
       "0      RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...   \n",
       "1      retirement ages. In paper find absence age-rel...   \n",
       "2      NBER lfriedberg virginia.edu Anthony Webb Inte...   \n",
       "3      in 1983 to 44% in 1998.1 Pension wealth in tra...   \n",
       "4      early on in order to gain access to large futu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage steady state consumptio...   \n",
       "19615  The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...   \n",
       "19616  1.04 0.00 0.02 0.01  Stochastic steady state d...   \n",
       "19617  -0.086 -0.081 capital stock (foreign) 0.431 0....   \n",
       "19618  u-overall (foreign) -0.751 -0.416 -0.491 -0.46...   \n",
       "\n",
       "                                               file_path  \n",
       "0      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "1      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "2      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "3      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "4      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "...                                                  ...  \n",
       "19614  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19615  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19616  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19617  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19618  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "\n",
       "[19619 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TESTING\n",
    "# Importing a lot of PDFs to see how long this takes\n",
    "papers_repo = r\"C:\\Users\\Steven\\Documents\\Python\\Data\\NBER papers\"\n",
    "\n",
    "files = os.listdir(papers_repo)\n",
    "files.sort(reverse=True)\n",
    "\n",
    "full_dict = {\n",
    "    'raw_chunk': []\n",
    "    , 'processed_chunk': []\n",
    "    , 'file_path': []\n",
    "}\n",
    "\n",
    "counter=1\n",
    "\n",
    "for paper in files[0:100]:\n",
    "    f = f\"{papers_repo}/{paper}\"\n",
    "    iter_dict = prepare_PDF(f)\n",
    "    full_dict['raw_chunk'].extend(iter_dict['raw_chunk'])\n",
    "    full_dict['processed_chunk'].extend(iter_dict['processed_chunk'])\n",
    "    full_dict['file_path'].extend(iter_dict['file_path'])\n",
    "    if counter%5==0:\n",
    "        print(f\"Finished filed {counter}.\")\n",
    "    counter+=1\n",
    "\n",
    "df = pd.DataFrame.from_dict(full_dict)\n",
    "df\n",
    "\n",
    "# Currently takes around 1 second per file (with tokenization chunking)\n",
    "# Takes ~ 0.7 seconds with approximate chunking\n",
    "# After switching to PyMuPDF, 0.1 seconds per file, but 3 cmsOpenProfileFromMem errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...</td>\n",
       "      <td>RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.52801526, 0.42685816, 0.7900874, -2.884799,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>retirement ages. In this paper we find that th...</td>\n",
       "      <td>retirement ages. In paper find absence age-rel...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.10414995, 1.8608961, -0.58080816, -3.008655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...</td>\n",
       "      <td>NBER lfriedberg virginia.edu Anthony Webb Inte...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.413939, 2.5478559, -0.47449192, -3.7103095,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1983 to 44% in 1998.1  \\nPension wealth in ...</td>\n",
       "      <td>in 1983 to 44% in 1998.1 Pension wealth in tra...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.7579198, 0.9669083, -1.406159, -2.7612479, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>early on in order to gain access to \\nlarge fu...</td>\n",
       "      <td>early on in order to gain access to large futu...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.0870267, 0.1609143, -1.9778296, -2.9505513,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>effects (as percentage of steady state consump...</td>\n",
       "      <td>effects (as percentage steady state consumptio...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-1.0131456, -0.84284586, 2.846375, 1.1860936,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...</td>\n",
       "      <td>The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.38758105, -0.39671537, 0.31152856, 0.02586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>\\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...</td>\n",
       "      <td>1.04 0.00 0.02 0.01  Stochastic steady state d...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.30377403, -0.79760385, -0.4383789, 0.20054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19617</th>\n",
       "      <td>\\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...</td>\n",
       "      <td>-0.086 -0.081 capital stock (foreign) 0.431 0....</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.25683185, -1.5001143, 0.6960092, 0.1808855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>\\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....</td>\n",
       "      <td>u-overall (foreign) -0.751 -0.416 -0.491 -0.46...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.8847793, -1.5567167, 1.9680667, 0.14790502...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_chunk  \\\n",
       "0      NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...   \n",
       "1      retirement ages. In this paper we find that th...   \n",
       "2      NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...   \n",
       "3      in 1983 to 44% in 1998.1  \\nPension wealth in ...   \n",
       "4      early on in order to gain access to \\nlarge fu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage of steady state consump...   \n",
       "19615  The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...   \n",
       "19616  \\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...   \n",
       "19617  \\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...   \n",
       "19618  \\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....   \n",
       "\n",
       "                                         processed_chunk  \\\n",
       "0      RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...   \n",
       "1      retirement ages. In paper find absence age-rel...   \n",
       "2      NBER lfriedberg virginia.edu Anthony Webb Inte...   \n",
       "3      in 1983 to 44% in 1998.1 Pension wealth in tra...   \n",
       "4      early on in order to gain access to large futu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage steady state consumptio...   \n",
       "19615  The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...   \n",
       "19616  1.04 0.00 0.02 0.01  Stochastic steady state d...   \n",
       "19617  -0.086 -0.081 capital stock (foreign) 0.431 0....   \n",
       "19618  u-overall (foreign) -0.751 -0.416 -0.491 -0.46...   \n",
       "\n",
       "                                               file_path  \\\n",
       "0      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "1      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "2      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "3      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "4      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "...                                                  ...   \n",
       "19614  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19615  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19616  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19617  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19618  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "\n",
       "                                                  vector  \n",
       "0      [0.52801526, 0.42685816, 0.7900874, -2.884799,...  \n",
       "1      [0.10414995, 1.8608961, -0.58080816, -3.008655...  \n",
       "2      [1.413939, 2.5478559, -0.47449192, -3.7103095,...  \n",
       "3      [1.7579198, 0.9669083, -1.406159, -2.7612479, ...  \n",
       "4      [1.0870267, 0.1609143, -1.9778296, -2.9505513,...  \n",
       "...                                                  ...  \n",
       "19614  [-1.0131456, -0.84284586, 2.846375, 1.1860936,...  \n",
       "19615  [-0.38758105, -0.39671537, 0.31152856, 0.02586...  \n",
       "19616  [-0.30377403, -0.79760385, -0.4383789, 0.20054...  \n",
       "19617  [-0.25683185, -1.5001143, 0.6960092, 0.1808855...  \n",
       "19618  [-0.8847793, -1.5567167, 1.9680667, 0.14790502...  \n",
       "\n",
       "[19619 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = model.encode(df['processed_chunk'])\n",
    "# This returns a np array of shape (n, d), where n is \n",
    "#     number of chunks and d is embedding dimensions.\n",
    "\n",
    "df['vector'] = [i for i in np.unstack(vecs)]\n",
    "# Add the embeddings to our dataframe in a single variable,\n",
    "#     so each cell contains the d-dimensional np vector.\n",
    "\n",
    "df\n",
    "# takes 3-4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9999.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9998.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9997.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9996.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9995.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9994.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9993.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9992.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9991.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9990.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9989.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9988.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9987.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9986.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9985.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9984.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9983.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9982.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9981.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9980.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9979.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9978.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9977.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9976.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9975.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9974.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9973.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9972.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9971.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9970.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9969.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9968.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9967.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9966.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9965.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9964.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9963.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9962.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9961.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9960.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9959.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9958.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9957.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9956.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9955.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9954.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9953.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9952.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9951.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9950.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9949.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9948.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9947.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9946.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9945.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9944.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9943.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9942.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9941.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9940.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9939.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9938.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9937.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9936.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9935.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9934.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9933.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9932.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9931.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9930.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9929.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9928.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9927.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9926.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9925.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9924.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9923.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9922.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9921.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9920.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9919.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9918.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9917.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9916.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9915.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9914.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9913.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9912.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9911.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9910.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9909.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9908.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9907.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9906.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9905.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9904.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9903.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9902.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9901.pdf',\n",
       "       'C:\\\\Users\\\\Steven\\\\Documents\\\\Python\\\\Data\\\\NBER papers/9900.pdf'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing querying the index\n",
    "\n",
    "query = 'founding fathers america free trade' # reference to paper 9943\n",
    "\n",
    "# Encode the query\n",
    "query_vec = model.encode(query)\n",
    "\n",
    "# Search for nearest neighbors in the df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
