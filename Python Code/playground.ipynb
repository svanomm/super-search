{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sevan\\Documents\\GitHub\\super-search\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import StaticEmbedding\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pynndescent as nn\n",
    "\n",
    "# Add the current directory to the path\n",
    "sys.path.append(os.getcwd())\n",
    "from preprocess import prepare_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(r\"C:\\Users\\Steven\\Desktop\\*.pdf\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "main = r\"C:\\Users\\Steven\\Documents\\Python\\super-search\"\n",
    "data = f\"{main}/data/tests\"\n",
    "test_file = f\"{data}/32286.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nPROMOTING PUBLIC HE...</td>\n",
       "      <td>PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32286\\nMarch 2024\\nJEL No. H70,I1,I11,J20\\nABS...</td>\n",
       "      <td>32286 March 2024 JEL No. H70,I1,I11,J20 study ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drawn to healthcare, relaxing shortages. On th...</td>\n",
       "      <td>drawn to healthcare, relaxing shortages. On ot...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and out of the industry. Our findings suggest ...</td>\n",
       "      <td>and out industry. findings suggest vaccine man...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Findings \\nsuggest trade-offs faced by health ...</td>\n",
       "      <td>Findings suggest trade-offs faced health polic...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>vertical lines.\\n55\\n Table A1: Healthcare ind...</td>\n",
       "      <td>vertical lines. 55 Table A1 Healthcare industr...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>(Flood et al., 2023).\\n56\\n Table A2: Healthca...</td>\n",
       "      <td>(Flood et al., 2023). 56 Table A2 Healthcare O...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>and ophthalmic medical technician\\nall other\\n...</td>\n",
       "      <td>and ophthalmic medical technician all other 35...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Population Survey. We use the variable OCC inc...</td>\n",
       "      <td>Population Survey. use variable OCC included i...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>current\\nemployment status, ages 21-64, with a...</td>\n",
       "      <td>current employment status, ages 21-64, additio...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_chunk  \\\n",
       "0    NBER WORKING PAPER SERIES\\nPROMOTING PUBLIC HE...   \n",
       "1    32286\\nMarch 2024\\nJEL No. H70,I1,I11,J20\\nABS...   \n",
       "2    drawn to healthcare, relaxing shortages. On th...   \n",
       "3    and out of the industry. Our findings suggest ...   \n",
       "4    Findings \\nsuggest trade-offs faced by health ...   \n",
       "..                                                 ...   \n",
       "242  vertical lines.\\n55\\n Table A1: Healthcare ind...   \n",
       "243  (Flood et al., 2023).\\n56\\n Table A2: Healthca...   \n",
       "244  and ophthalmic medical technician\\nall other\\n...   \n",
       "245  Population Survey. We use the variable OCC inc...   \n",
       "246  current\\nemployment status, ages 21-64, with a...   \n",
       "\n",
       "                                       processed_chunk  \\\n",
       "0    PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS...   \n",
       "1    32286 March 2024 JEL No. H70,I1,I11,J20 study ...   \n",
       "2    drawn to healthcare, relaxing shortages. On ot...   \n",
       "3    and out industry. findings suggest vaccine man...   \n",
       "4    Findings suggest trade-offs faced health polic...   \n",
       "..                                                 ...   \n",
       "242  vertical lines. 55 Table A1 Healthcare industr...   \n",
       "243  (Flood et al., 2023). 56 Table A2 Healthcare O...   \n",
       "244  and ophthalmic medical technician all other 35...   \n",
       "245  Population Survey. use variable OCC included i...   \n",
       "246  current employment status, ages 21-64, additio...   \n",
       "\n",
       "                                             file_path  \n",
       "0    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "1    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "2    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "3    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "4    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "..                                                 ...  \n",
       "242  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "243  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "244  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "245  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "246  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "\n",
       "[247 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(prepare_PDF(test_file))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS EVIDENCE FROM VACCINE MANDATES Rahi Abouk John S. Earle Johanna Catherine Maclean Sungbin Park Working Paper 32286 http //www.nber.org/papers/w32286 1050 Massachusetts Avenue Cambridge, MA 02138 March 2024 Research reported in publication supported National Institute on Mental Health National Institutes Health under Award Number 1R01MH132552 (PI Johanna Catherine Maclean). John Earle also acknowledges support Russell Sage Foundation. views expressed herein authors not necessarily reflect views National Institutes Health or. NBER working papers circulated discussion comment purposes. not peer-reviewed or subject to review NBER Board Directors accompanies official NBER publications. 2024 Rahi Abouk, John S. Earle, Johanna Catherine Maclean, Sungbin Park. All rights reserved. Short sections text, not to exceed two paragraphs, may quoted without explicit permission provided full credit, including notice, given to source. Promoting Public Health Blunt Instruments Evidence Vaccine Mandates Rahi Abouk, John S. Earle, Johanna Catherine Maclean, Sungbin Park NBER Working Paper No. 32286 March 2024 JEL No. H70,I1,I11,J20 study effect mandates requiring COVID-19 vaccination among healthcare industry workers adopted in 2021 in United States. There long-standing worker shortages in U.S. healthcare industry, pre-dating COVID-19 pandemic. impact COVID-19 vaccine mandates on shortages ex ante ambiguous. If mandates increase perceived safety healthcare industry, marginal workers may'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_PDF(test_file)['processed_chunk'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do:\n",
    "\n",
    "### Database management\n",
    "-~~ We need a system to handle vector database as well as allowing for fast retrieval of the files corresponding to each vector~~\n",
    "    - ~~Each file needs a file_id~~\n",
    "        - ~~Links to the filepath~~\n",
    "    - ~~Each chunk needs a chunk_id~~\n",
    "        - ~~Links to the chunk text~~\n",
    "            - ~~Importantly, link to the original text, not the processed text used for embedding.~~\n",
    "                - ~~**I think the solution is to do the sentence chunking on the original text, before processing**~~\n",
    "    - ~~file_id + chunk_id should uniquely identify a vector in the database~~\n",
    "- ~~After taking a user query and encoding it, perform similarity search in the database\n",
    "    to identify a row, then link to the row's filepath and text~~\n",
    "- ~~Then print a hyperlink to the file, and print the original text~~\n",
    "- **Problem**: how to return images, given that we first caption them with an LLM and then encode the caption?\n",
    "    - Also, should we treat each image description as a chunk, or subchunk the images for more accuracy?\n",
    "\n",
    "### Lexical search\n",
    "- Use bm25s package to create ngram indices\n",
    "- Incorporate lexical search into the queries to improve accuracy on exact matches to key phrases.\n",
    "\n",
    "### Misc.\n",
    "- Parallelized PDF processing\n",
    "- Timing everything to understand where the bottlenecks are\n",
    "- Save performance statistics to report in the app\n",
    "    - How many PDF pages have been read? \n",
    "- ~~Switch to PyMuPDF~~ (It's much faster!!!)\n",
    "- ~~Save page number to the index~~\n",
    "    - ~~This actually doesn't seem possible because chunking works by combining all text to a single line.~~\n",
    "- Allow to read text files, including code (.py, .R, .do, .sql)\n",
    "    - pymupdf can do this\n",
    "\n",
    "### Incorporating Images\n",
    "- Use PyMuPDF to extract images from each page of the PDF.\n",
    "- Goal is to pass each image to a multi-modal LLM for summary, which is then fed into the cleaned text.\n",
    "    - Possibly LLaVA for describing the images.\n",
    "    - Since captioning the images would take a super long time, this should be an optional step.\n",
    "        - Ideally would be done after first parsing the text, but then you might have to regenerate the whole vector base\n",
    "- **Why not just use an image encoder directly (if available)? Is it bad to mix embeddings from different encoders? probably**\n",
    "    - Instead could encode images separately from the text, and have a separate search function for them.\n",
    "\n",
    "### GUI\n",
    "- The following should be customizable inputs:\n",
    "    - Chunk token size (\"larger is faster but less accurate\") (default: 256)\n",
    "    - Chunk overlap (\"larger gives more context per chunk\") (default: chunk_size / 4)\n",
    "    - Choice of sentence transformer: provide a few options based on speed/accuracy tradeoff.\n",
    "        - Fastest: static-retrieval-mrl-en-v1\n",
    "        - Medium: bge-m3\n",
    "        - Slowest: gte-large-en-v1.5\n",
    "        - (these are subject to change)\n",
    "    - Index database save location\n",
    "    - Similarity matrix (default: cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current encoding model implementation: static-retrieval-mrl-en-v1\n",
    "# https://huggingface.co/sentence-transformers/static-retrieval-mrl-en-v1\n",
    "# Model defaults to 1024 dense dimensions, but can be truncated to save space/time\n",
    "\n",
    "truncated_dimensions = 1024\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/static-retrieval-mrl-en-v1\"\n",
    "    , device=\"cpu\"\n",
    "    , truncate_dim=truncated_dimensions\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished filed 5.\n",
      "Finished filed 10.\n",
      "Finished filed 15.\n",
      "Finished filed 20.\n",
      "Finished filed 25.\n",
      "Finished filed 30.\n",
      "Finished filed 35.\n",
      "Finished filed 40.\n",
      "Finished filed 45.\n",
      "Finished filed 50.\n",
      "Finished filed 55.\n",
      "Finished filed 60.\n",
      "Finished filed 65.\n",
      "Finished filed 70.\n",
      "Finished filed 75.\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "Finished filed 80.\n",
      "Finished filed 85.\n",
      "Finished filed 90.\n",
      "Finished filed 95.\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "Finished filed 100.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...</td>\n",
       "      <td>RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>retirement ages. In this paper we find that th...</td>\n",
       "      <td>retirement ages. In paper find absence age-rel...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...</td>\n",
       "      <td>NBER lfriedberg virginia.edu Anthony Webb Inte...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1983 to 44% in 1998.1  \\nPension wealth in ...</td>\n",
       "      <td>in 1983 to 44% in 1998.1 Pension wealth in tra...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>early on in order to gain access to \\nlarge fu...</td>\n",
       "      <td>early on in order to gain access to large futu...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>effects (as percentage of steady state consump...</td>\n",
       "      <td>effects (as percentage steady state consumptio...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...</td>\n",
       "      <td>The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>\\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...</td>\n",
       "      <td>1.04 0.00 0.02 0.01  Stochastic steady state d...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19617</th>\n",
       "      <td>\\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...</td>\n",
       "      <td>-0.086 -0.081 capital stock (foreign) 0.431 0....</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>\\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....</td>\n",
       "      <td>u-overall (foreign) -0.751 -0.416 -0.491 -0.46...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19619 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_chunk  \\\n",
       "0      NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...   \n",
       "1      retirement ages. In this paper we find that th...   \n",
       "2      NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...   \n",
       "3      in 1983 to 44% in 1998.1  \\nPension wealth in ...   \n",
       "4      early on in order to gain access to \\nlarge fu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage of steady state consump...   \n",
       "19615  The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...   \n",
       "19616  \\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...   \n",
       "19617  \\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...   \n",
       "19618  \\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....   \n",
       "\n",
       "                                         processed_chunk  \\\n",
       "0      RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...   \n",
       "1      retirement ages. In paper find absence age-rel...   \n",
       "2      NBER lfriedberg virginia.edu Anthony Webb Inte...   \n",
       "3      in 1983 to 44% in 1998.1 Pension wealth in tra...   \n",
       "4      early on in order to gain access to large futu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage steady state consumptio...   \n",
       "19615  The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...   \n",
       "19616  1.04 0.00 0.02 0.01  Stochastic steady state d...   \n",
       "19617  -0.086 -0.081 capital stock (foreign) 0.431 0....   \n",
       "19618  u-overall (foreign) -0.751 -0.416 -0.491 -0.46...   \n",
       "\n",
       "                                               file_path  \n",
       "0      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "1      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "2      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "3      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "4      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "...                                                  ...  \n",
       "19614  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19615  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19616  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19617  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "19618  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "\n",
       "[19619 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TESTING\n",
    "# Importing a lot of PDFs to see how long this takes\n",
    "papers_repo = r\"C:\\Users\\Steven\\Documents\\Python\\Data\\NBER papers\"\n",
    "\n",
    "files = os.listdir(papers_repo)\n",
    "files.sort(reverse=True)\n",
    "\n",
    "full_dict = {\n",
    "    'raw_chunk': []\n",
    "    , 'processed_chunk': []\n",
    "    , 'file_path': []\n",
    "}\n",
    "\n",
    "counter=1\n",
    "\n",
    "for paper in files[0:100]:\n",
    "    f = f\"{papers_repo}/{paper}\"\n",
    "    iter_dict = prepare_PDF(f)\n",
    "    full_dict['raw_chunk'].extend(iter_dict['raw_chunk'])\n",
    "    full_dict['processed_chunk'].extend(iter_dict['processed_chunk'])\n",
    "    full_dict['file_path'].extend(iter_dict['file_path'])\n",
    "    if counter%5==0:\n",
    "        print(f\"Finished file {counter}.\")\n",
    "    counter+=1\n",
    "\n",
    "df = pd.DataFrame.from_dict(full_dict)\n",
    "df\n",
    "\n",
    "# Currently takes around 1 second per file (with tokenization chunking)\n",
    "# Takes ~ 0.7 seconds with approximate chunking\n",
    "# After switching to PyMuPDF, 0.1 seconds per file, but 3 cmsOpenProfileFromMem errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...</td>\n",
       "      <td>RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.52801526, 0.42685816, 0.7900874, -2.884799,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>retirement ages. In this paper we find that th...</td>\n",
       "      <td>retirement ages. In paper find absence age-rel...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.10414995, 1.8608961, -0.58080816, -3.008655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...</td>\n",
       "      <td>NBER lfriedberg virginia.edu Anthony Webb Inte...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.413939, 2.5478559, -0.47449192, -3.7103095,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1983 to 44% in 1998.1  \\nPension wealth in ...</td>\n",
       "      <td>in 1983 to 44% in 1998.1 Pension wealth in tra...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.7579198, 0.9669083, -1.406159, -2.7612479, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>early on in order to gain access to \\nlarge fu...</td>\n",
       "      <td>early on in order to gain access to large futu...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.0870267, 0.1609143, -1.9778296, -2.9505513,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>effects (as percentage of steady state consump...</td>\n",
       "      <td>effects (as percentage steady state consumptio...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-1.0131456, -0.84284586, 2.846375, 1.1860936,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...</td>\n",
       "      <td>The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.38758105, -0.39671537, 0.31152856, 0.02586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>\\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...</td>\n",
       "      <td>1.04 0.00 0.02 0.01  Stochastic steady state d...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.30377403, -0.79760385, -0.4383789, 0.20054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19617</th>\n",
       "      <td>\\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...</td>\n",
       "      <td>-0.086 -0.081 capital stock (foreign) 0.431 0....</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.25683185, -1.5001143, 0.6960092, 0.1808855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>\\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....</td>\n",
       "      <td>u-overall (foreign) -0.751 -0.416 -0.491 -0.46...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.8847793, -1.5567167, 1.9680667, 0.14790502...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_chunk  \\\n",
       "0      NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...   \n",
       "1      retirement ages. In this paper we find that th...   \n",
       "2      NBER\\nlfriedberg@virginia.edu\\nAnthony Webb\\nI...   \n",
       "3      in 1983 to 44% in 1998.1  \\nPension wealth in ...   \n",
       "4      early on in order to gain access to \\nlarge fu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage of steady state consump...   \n",
       "19615  The policy rule is \\nˆ\\n5.0\\n0.0\\n0.0\\nt\\nt\\nt...   \n",
       "19616  \\n1.04 \\n0.00 \\n0.02 \\n0.01 \\n \\n \\n \\n \\n \\nS...   \n",
       "19617  \\n-0.086 \\n-0.081 \\n capital stock (foreign) \\...   \n",
       "19618  \\n u-overall (foreign) \\n-0.751 \\n-0.416 \\n-0....   \n",
       "\n",
       "                                         processed_chunk  \\\n",
       "0      RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...   \n",
       "1      retirement ages. In paper find absence age-rel...   \n",
       "2      NBER lfriedberg virginia.edu Anthony Webb Inte...   \n",
       "3      in 1983 to 44% in 1998.1 Pension wealth in tra...   \n",
       "4      early on in order to gain access to large futu...   \n",
       "...                                                  ...   \n",
       "19614  effects (as percentage steady state consumptio...   \n",
       "19615  The policy rule ˆ 5.0 0.0 0.0 t t t t i Y s π ...   \n",
       "19616  1.04 0.00 0.02 0.01  Stochastic steady state d...   \n",
       "19617  -0.086 -0.081 capital stock (foreign) 0.431 0....   \n",
       "19618  u-overall (foreign) -0.751 -0.416 -0.491 -0.46...   \n",
       "\n",
       "                                               file_path  \\\n",
       "0      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "1      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "2      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "3      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "4      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "...                                                  ...   \n",
       "19614  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19615  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19616  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19617  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "19618  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "\n",
       "                                                  vector  \n",
       "0      [0.52801526, 0.42685816, 0.7900874, -2.884799,...  \n",
       "1      [0.10414995, 1.8608961, -0.58080816, -3.008655...  \n",
       "2      [1.413939, 2.5478559, -0.47449192, -3.7103095,...  \n",
       "3      [1.7579198, 0.9669083, -1.406159, -2.7612479, ...  \n",
       "4      [1.0870267, 0.1609143, -1.9778296, -2.9505513,...  \n",
       "...                                                  ...  \n",
       "19614  [-1.0131456, -0.84284586, 2.846375, 1.1860936,...  \n",
       "19615  [-0.38758105, -0.39671537, 0.31152856, 0.02586...  \n",
       "19616  [-0.30377403, -0.79760385, -0.4383789, 0.20054...  \n",
       "19617  [-0.25683185, -1.5001143, 0.6960092, 0.1808855...  \n",
       "19618  [-0.8847793, -1.5567167, 1.9680667, 0.14790502...  \n",
       "\n",
       "[19619 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = model.encode(df['processed_chunk'])\n",
    "# This returns a np array of shape (n, d), where n is \n",
    "#     number of chunks and d is embedding dimensions.\n",
    "\n",
    "df['vector'] = [i for i in np.unstack(vecs)]\n",
    "# Add the embeddings to our dataframe in a single variable,\n",
    "#     so each cell contains the d-dimensional np vector.\n",
    "\n",
    "df\n",
    "# takes 3-4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing querying the index\n",
    "\n",
    "query = 'Madison and Jefferson reaction in January and February 1792' # reference to paper 9943\n",
    "\n",
    "# Encode the query\n",
    "query_vec = model.encode(query)\n",
    "\n",
    "# Search for nearest neighbors in the df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19619, 1024)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = nn.NNDescent(vecs)\n",
    "index.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[10829, 10830, 10851]], dtype=int32),\n",
       " array([[133.33989, 139.48766, 140.08379]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(query_vec.reshape(1,-1), k=3)\n",
    "# 10829, 10830, 10851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strikingly similar to Hamilton’s earlier report that Jefferson and\n",
      " -3-\n",
      "1  Annals of Congress, 1 (January 8, 1790), p. 969.\n",
      "2  Annals of Congress, 1 (January 15, 1790), p. 1095.\n",
      "Madison opposed.  \n",
      "Given the report’s importance in the history of U.S. economic policy, this paper explores\n",
      "the reception and immediate legislative impact of the report.  After briefly reviewing the\n",
      "contents and proposals in the December 1791 report, the paper turns to Madison’s and\n",
      "Jefferson’s reaction to it in January and February 1792.  In February and March 1792, Congress\n",
      "debated bounties for the cod fisheries and additional revenue proposals involving tariffs, both of\n",
      "which related to Hamilton’s report.  Finally, the paper examines the turn of manufacturing\n",
      "interests away from the Federalists as the Jeffersonian Republican policy of reciprocity offered\n",
      "the hope of\n",
      "C:\\Users\\Steven\\Documents\\Python\\Data\\NBER papers/9943.pdf\n",
      "1791 report, the paper turns to Madison’s and\n",
      "Jefferson’s reaction to it in January and February 1792.  In February and March 1792, Congress\n",
      "debated bounties for the cod fisheries and additional revenue proposals involving tariffs, both of\n",
      "which related to Hamilton’s report.  Finally, the paper examines the turn of manufacturing\n",
      "interests away from the Federalists as the Jeffersonian Republican policy of reciprocity offered\n",
      "the hope of greater relief from foreign competition than Hamilton’s revenue-based trade policy.\n",
      "Hamilton’s Report on Manufactures\n",
      "In his first annual message to Congress on January 8, 1790, President George\n",
      "Washington noted that the safety and interest of a free people “require that they should promote\n",
      "such manufactories as tend to render them independent of others for essential, particularly\n",
      "military, supplies.”1  Seven days later, the House of Representatives requested that the\n",
      "C:\\Users\\Steven\\Documents\\Python\\Data\\NBER papers/9943.pdf\n",
      "the\n",
      "objects are unlimited, the parchment had better be thrown into the fire at once.”7\n",
      " -8-\n",
      "special powers reserved out of it.”  Papers of James Madison, Vol. 14 (January 21, 1792), p. 193.\n",
      "8  Papers of James Madison, Vol. 14 (January 21, 1792), p. 195.\n",
      "9  Papers of Thomas Jefferson, Vol. 23 (February 29, 1792), pp. 172-173.\n",
      "To another correspondent, Madison complained that, because Hamilton’s report  \n",
      "“broaches a new constitutional doctrine of vast consequence and demanding the serious\n",
      "attention of the public, I consider it myself as subverting the fundamental and\n",
      "characteristic principle of the Government, as contrary to the true & fair, as well as the\n",
      "received construction, and as bidding defiance to the sense in which the Constitution is\n",
      "known to have been proposed, advocated and adopted.  If Congress\n",
      "C:\\Users\\Steven\\Documents\\Python\\Data\\NBER papers/9943.pdf\n"
     ]
    }
   ],
   "source": [
    "for i in [10829, 10830, 10851]:\n",
    "    print(df['raw_chunk'][i])\n",
    "    print(df['file_path'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable '_chunk_size' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# chunk the raw text\u001b[39;00m\n\u001b[0;32m     20\u001b[0m chunker \u001b[38;5;241m=\u001b[39m setup_chunker()\n\u001b[1;32m---> 21\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43mchunker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper_one_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Organize chunks and processed chunks into a dictionary\u001b[39;00m\n\u001b[0;32m     24\u001b[0m chunk_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_chunk\u001b[39m\u001b[38;5;124m'\u001b[39m: [chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     26\u001b[0m     , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_chunk\u001b[39m\u001b[38;5;124m'\u001b[39m: [preprocess(chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     27\u001b[0m     , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m'\u001b[39m: [in_path \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     28\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\sevan\\Documents\\GitHub\\super-search\\Python Code\\preprocess.py:21\u001b[0m, in \u001b[0;36msetup_chunker.<locals>.chunker\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     18\u001b[0m words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_chunk_size\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(words):\n\u001b[0;32m     22\u001b[0m     _chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(words)\n\u001b[0;32m     24\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable '_chunk_size' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "from preprocess import *\n",
    "\n",
    "in_path=r\"C:\\Users\\sevan\\Desktop\\Meet with Prof. Fulton.txt\"\n",
    "doc = pymupdf.open(in_path)\n",
    "\n",
    "# combine all pages into one list\n",
    "paper = []\n",
    "for page in doc:\n",
    "    # extract text from page\n",
    "    page_text = page.get_text()\n",
    "\n",
    "    # append to paper\n",
    "    paper.append(page_text)\n",
    "\n",
    "# convert list into string\n",
    "paper_one_string = ' '.join(paper)\n",
    "\n",
    "# chunk the raw text\n",
    "chunker = setup_chunker()\n",
    "chunks = chunker(paper_one_string)\n",
    "\n",
    "# Organize chunks and processed chunks into a dictionary\n",
    "chunk_data = {\n",
    "    'raw_chunk': [chunk for chunk in chunks]\n",
    "    , 'processed_chunk': [preprocess(chunk) for chunk in chunks]\n",
    "    , 'file_path': [in_path for chunk in chunks]\n",
    "}\n",
    "\n",
    "chunk_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
