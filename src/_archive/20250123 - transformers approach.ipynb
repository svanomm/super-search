{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sentence-transformers) (4.48.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sentence-transformers) (0.27.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chonkie in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: autotiktokenizer>=0.2.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from chonkie) (0.2.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from chonkie) (4.67.1)\n",
      "Requirement already satisfied: tiktoken>=0.2.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from autotiktokenizer>=0.2.0->chonkie) (0.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from autotiktokenizer>=0.2.0->chonkie) (0.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from tqdm>=4.64.0->chonkie) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from tiktoken>=0.2.0->autotiktokenizer>=0.2.0->chonkie) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.0.12->autotiktokenizer>=0.2.0->chonkie) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pypdf[image] in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (5.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\steven\\documents\\python\\super-search\\.venv\\lib\\site-packages (from pypdf[image]) (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE:\n",
    "Before running this, create a virtual environment running\n",
    "Python 3.12\n",
    "\"\"\" \n",
    "# pytorch install, cpu-only\n",
    "%pip install torch \n",
    "%pip install transformers\n",
    "%pip install sentence-transformers\n",
    "%pip install pandas\n",
    "%pip install chonkie\n",
    "%pip install pypdf[image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import StaticEmbedding\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Add the current directory to the path\n",
    "sys.path.append(os.getcwd())\n",
    "from preprocess import prepare_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "main = r\"C:\\Users\\Steven\\Documents\\Python\\super-search\"\n",
    "data = f\"{main}/data/tests\"\n",
    "test_file = f\"{data}/32286.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nPROMOTING PUBLIC HE...</td>\n",
       "      <td>PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBER publications.\\n© 2024 by Rahi Abouk, John...</td>\n",
       "      <td>NBER publications. 2024 Rahi Abouk, John S. Ea...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If mandates increase perceived safety of the ...</td>\n",
       "      <td>If mandates increase perceived safety healthca...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mandates and are slower to be replaced than wo...</td>\n",
       "      <td>mandates slower to replaced than workers in no...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edu 1 Introduction\\nThe COVID-19 pandemic - li...</td>\n",
       "      <td>edu 1 Introduction COVID-19 pandemic - like ot...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Exitt Entert\\nMandate states, Non-mandate Mand...</td>\n",
       "      <td>Exitt Entert Mandate states, Non-mandate Manda...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Among HCO 0.0539 0.0492 0.0531 0.0481\\n(obs: 7...</td>\n",
       "      <td>Among HCO 0.0539 0.0492 0.0531 0.0481 (obs 7,0...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>50-59 years 0.22 0.22 0.22 0.22\\n60-64 years 0...</td>\n",
       "      <td>50-59 years 0.22 0.22 0.22 0.22 60-64 years 0....</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Less than high school 0.02 0.02 0.02 0.02\\nHig...</td>\n",
       "      <td>Less than high school 0.02 0.02 0.02 0.02 High...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>vaccine mandate\\nGov’t worker COVID-19 0.05 0....</td>\n",
       "      <td>vaccine mandate Gov’t worker COVID-19 0.05 0.0...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\super-search/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_chunk  \\\n",
       "0    NBER WORKING PAPER SERIES\\nPROMOTING PUBLIC HE...   \n",
       "1    NBER publications.\\n© 2024 by Rahi Abouk, John...   \n",
       "2     If mandates increase perceived safety of the ...   \n",
       "3    mandates and are slower to be replaced than wo...   \n",
       "4    edu 1 Introduction\\nThe COVID-19 pandemic - li...   \n",
       "..                                                 ...   \n",
       "184  Exitt Entert\\nMandate states, Non-mandate Mand...   \n",
       "185  Among HCO 0.0539 0.0492 0.0531 0.0481\\n(obs: 7...   \n",
       "186  50-59 years 0.22 0.22 0.22 0.22\\n60-64 years 0...   \n",
       "187  Less than high school 0.02 0.02 0.02 0.02\\nHig...   \n",
       "188  vaccine mandate\\nGov’t worker COVID-19 0.05 0....   \n",
       "\n",
       "                                       processed_chunk  \\\n",
       "0    PROMOTING PUBLIC HEALTH WITH BLUNT INSTRUMENTS...   \n",
       "1    NBER publications. 2024 Rahi Abouk, John S. Ea...   \n",
       "2    If mandates increase perceived safety healthca...   \n",
       "3    mandates slower to replaced than workers in no...   \n",
       "4    edu 1 Introduction COVID-19 pandemic - like ot...   \n",
       "..                                                 ...   \n",
       "184  Exitt Entert Mandate states, Non-mandate Manda...   \n",
       "185  Among HCO 0.0539 0.0492 0.0531 0.0481 (obs 7,0...   \n",
       "186  50-59 years 0.22 0.22 0.22 0.22 60-64 years 0....   \n",
       "187  Less than high school 0.02 0.02 0.02 0.02 High...   \n",
       "188  vaccine mandate Gov’t worker COVID-19 0.05 0.0...   \n",
       "\n",
       "                                             file_path  \n",
       "0    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "1    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "2    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "3    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "4    C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "..                                                 ...  \n",
       "184  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "185  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "186  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "187  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "188  C:\\Users\\Steven\\Documents\\Python\\super-search/...  \n",
       "\n",
       "[189 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(prepare_PDF(test_file))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do:\n",
    "\n",
    "### Database management\n",
    "- We need a system to handle vector database as well as allowing for fast retrieval of the files corresponding to each vector\n",
    "    - Each file needs a file_id\n",
    "        - Links to the filepath\n",
    "    - Each chunk needs a chunk_id\n",
    "        - Links to the chunk text\n",
    "            - ~~Importantly, link to the original text, not the processed text used for embedding.~~\n",
    "                - ~~**I think the solution is to do the sentence chunking on the original text, before processing**~~\n",
    "    - file_id + chunk_id should uniquely identify a vector in the database\n",
    "- After taking a user query and encoding it, perform similarity search in the database\n",
    "    to identify a row, then link to the row's filepath and text\n",
    "- Then print a hyperlink to the file, and print the original text\n",
    "- **Problem**: how to return images, given that we first caption them with an LLM and then encode the caption?\n",
    "\n",
    "### Misc.\n",
    "- Parallelized PDF processing\n",
    "\n",
    "### Incorporating Images\n",
    "- Use PyPDF to extract images from each page of the PDF.\n",
    "```\n",
    "for page in reader.pages:\n",
    "    try:\n",
    "        for image in page.images:\n",
    "            extract_image(image)\n",
    "    except:\n",
    "        pass\n",
    "```\n",
    "- To render the image visually: image.image. Can also show as bytes\n",
    "- Goal is to pass each image to a multi-modal LLM for summary, which is then fed into the cleaned text.\n",
    "    - Possibly LLaVA for describing the images.\n",
    "    - Since captioning the images would take a super long time, this should be an optional step.\n",
    "        - Ideally would be done after first parsing the text, but then you might have to regenerate the whole vector base\n",
    "\n",
    "### GUI\n",
    "- The following should be customizable inputs:\n",
    "    - Chunk token size (\"larger is faster but less accurate\") (default: 256)\n",
    "    - Chunk overlap (\"larger gives more context per chunk\") (default: chunk_size / 4)\n",
    "    - Choice of sentence transformer: provide a few options based on speed/accuracy tradeoff.\n",
    "        - Fastest: static-retrieval-mrl-en-v1\n",
    "        - Medium: bge-m3\n",
    "        - Slowest: gte-large-en-v1.5\n",
    "        - (these are subject to change)\n",
    "    - Index database save location\n",
    "    - Similarity matrix (default: cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current encoding model implementation: static-retrieval-mrl-en-v1\n",
    "# https://huggingface.co/sentence-transformers/static-retrieval-mrl-en-v1\n",
    "# Model defaults to 1024 dense dimensions, but can be truncated to save space/time\n",
    "\n",
    "truncated_dimensions = 1024\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/static-retrieval-mrl-en-v1\"\n",
    "    , device=\"cpu\"\n",
    "    , truncate_dim=truncated_dimensions\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = model.encode(df['processed_chunk'])\n",
    "# This returns a np array of shape (n, d), where n is \n",
    "#     number of chunks and d is embedding dimensions.\n",
    "\n",
    "df2['vector'] = [i for i in np.unstack(vecs)]\n",
    "# Add the embeddings to our dataframe in a single variable,\n",
    "#     so each cell contains the d-dimensional np vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished filed 5.\n",
      "Finished filed 10.\n",
      "Finished filed 15.\n",
      "Finished filed 20.\n",
      "Finished filed 25.\n",
      "Finished filed 30.\n",
      "Finished filed 35.\n",
      "Finished filed 40.\n",
      "Finished filed 45.\n",
      "Finished filed 50.\n",
      "Finished filed 55.\n",
      "Finished filed 60.\n",
      "Finished filed 65.\n",
      "Finished filed 70.\n",
      "Finished filed 75.\n",
      "Finished filed 80.\n",
      "Finished filed 85.\n",
      "Finished filed 90.\n",
      "Finished filed 95.\n",
      "Finished filed 100.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...</td>\n",
       "      <td>RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All rights reserved. Short sections of text,...</td>\n",
       "      <td>All rights reserved. Short sections text, not ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thus, the evolution of pension structure can ...</td>\n",
       "      <td>Thus, evolution pension structure can help exp...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB pension wealth typically accumulates slow...</td>\n",
       "      <td>DB pension wealth typically accumulates slowly...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC pensions accumulate a lump sum which depe...</td>\n",
       "      <td>DC pensions accumulate lump sum which depends ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17557</th>\n",
       "      <td>786***     (.063)  (.137)   (.071)   (.096)   ...</td>\n",
       "      <td>786*** (.063) (.137) (.071) (.096) (.107) N 44...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>Total  Mixed Sex  Same Sex  Boys Only   Gi...</td>\n",
       "      <td>Total Mixed Sex Same Sex Boys Only Girls Only ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>141)  N    2364  698   1666   940   726   ***p...</td>\n",
       "      <td>141) N 2364 698 1666 940 726 ***p&lt;.001 **p&lt;.01...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17560</th>\n",
       "      <td>Infant Mortality  -.892***   -.703***   -.51...</td>\n",
       "      <td>Infant Mortality -.892*** -.703*** -.512*** (....</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17561</th>\n",
       "      <td>Everyone Same Sex Mixed (Fraternal) Identical\\...</td>\n",
       "      <td>Everyone Same Sex Mixed (Fraternal) Identical ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17562 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_chunk  \\\n",
       "0      NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...   \n",
       "1        All rights reserved. Short sections of text,...   \n",
       "2       Thus, the evolution of pension structure can ...   \n",
       "3        DB pension wealth typically accumulates slow...   \n",
       "4        DC pensions accumulate a lump sum which depe...   \n",
       "...                                                  ...   \n",
       "17557  786***     (.063)  (.137)   (.071)   (.096)   ...   \n",
       "17558      Total  Mixed Sex  Same Sex  Boys Only   Gi...   \n",
       "17559  141)  N    2364  698   1666   940   726   ***p...   \n",
       "17560    Infant Mortality  -.892***   -.703***   -.51...   \n",
       "17561  Everyone Same Sex Mixed (Fraternal) Identical\\...   \n",
       "\n",
       "                                         processed_chunk  \\\n",
       "0      RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...   \n",
       "1      All rights reserved. Short sections text, not ...   \n",
       "2      Thus, evolution pension structure can help exp...   \n",
       "3      DB pension wealth typically accumulates slowly...   \n",
       "4      DC pensions accumulate lump sum which depends ...   \n",
       "...                                                  ...   \n",
       "17557  786*** (.063) (.137) (.071) (.096) (.107) N 44...   \n",
       "17558  Total Mixed Sex Same Sex Boys Only Girls Only ...   \n",
       "17559  141) N 2364 698 1666 940 726 ***p<.001 **p<.01...   \n",
       "17560  Infant Mortality -.892*** -.703*** -.512*** (....   \n",
       "17561  Everyone Same Sex Mixed (Fraternal) Identical ...   \n",
       "\n",
       "                                               file_path  \n",
       "0      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "1      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "2      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "3      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "4      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "...                                                  ...  \n",
       "17557  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "17558  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "17559  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "17560  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "17561  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...  \n",
       "\n",
       "[17562 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TESTING\n",
    "# Importing a lot of PDFs to see how long this takes\n",
    "papers_repo = r\"C:\\Users\\Steven\\Documents\\Python\\Data\\NBER papers\"\n",
    "\n",
    "files = os.listdir(papers_repo)\n",
    "files.sort(reverse=True)\n",
    "\n",
    "full_dict = {\n",
    "    'raw_chunk': []\n",
    "    , 'processed_chunk': []\n",
    "    , 'file_path': []\n",
    "}\n",
    "\n",
    "counter=1\n",
    "\n",
    "for paper in files[0:99]:\n",
    "    f = f\"{papers_repo}/{paper}\"\n",
    "    iter_dict = prepare_PDF(f, tokenizer_model='minishlab/potion-base-8M')\n",
    "    full_dict['raw_chunk'].extend(iter_dict['raw_chunk'])\n",
    "    full_dict['processed_chunk'].extend(iter_dict['processed_chunk'])\n",
    "    full_dict['file_path'].extend(iter_dict['file_path'])\n",
    "    counter+=1\n",
    "    if counter%5==0:\n",
    "        print(f\"Finished filed {counter}.\")\n",
    "\n",
    "df = pd.DataFrame.from_dict(full_dict)\n",
    "df\n",
    "\n",
    "# Currently takes around 1 second per file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_chunk</th>\n",
       "      <th>processed_chunk</th>\n",
       "      <th>file_path</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...</td>\n",
       "      <td>RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.9494798, -0.5101314, 1.260272, -3.4051301, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All rights reserved. Short sections of text,...</td>\n",
       "      <td>All rights reserved. Short sections text, not ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.41856015, 0.94318783, -0.1712659, -3.14227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thus, the evolution of pension structure can ...</td>\n",
       "      <td>Thus, evolution pension structure can help exp...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.24726994, 1.506088, -0.993264, -2.7431295, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB pension wealth typically accumulates slow...</td>\n",
       "      <td>DB pension wealth typically accumulates slowly...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.8708433, 0.6725198, -2.1666236, -3.2994564,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC pensions accumulate a lump sum which depe...</td>\n",
       "      <td>DC pensions accumulate lump sum which depends ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[1.0445604, 0.36211833, -0.17084824, -1.149713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17557</th>\n",
       "      <td>786***     (.063)  (.137)   (.071)   (.096)   ...</td>\n",
       "      <td>786*** (.063) (.137) (.071) (.096) (.107) N 44...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.0041005667, -1.6556355, 2.509584, -0.22076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>Total  Mixed Sex  Same Sex  Boys Only   Gi...</td>\n",
       "      <td>Total Mixed Sex Same Sex Boys Only Girls Only ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.13459334, -1.6275283, 2.4162931, -0.3573123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>141)  N    2364  698   1666   940   726   ***p...</td>\n",
       "      <td>141) N 2364 698 1666 940 726 ***p&lt;.001 **p&lt;.01...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[0.07510667, -1.8058623, 2.654449, 0.3212689, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17560</th>\n",
       "      <td>Infant Mortality  -.892***   -.703***   -.51...</td>\n",
       "      <td>Infant Mortality -.892*** -.703*** -.512*** (....</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-0.8045424, -2.0775964, 1.3887693, 0.8446741,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17561</th>\n",
       "      <td>Everyone Same Sex Mixed (Fraternal) Identical\\...</td>\n",
       "      <td>Everyone Same Sex Mixed (Fraternal) Identical ...</td>\n",
       "      <td>C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...</td>\n",
       "      <td>[-2.1238828, -2.2521822, 2.0788414, 0.9449485,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17562 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_chunk  \\\n",
       "0      NBER WORKING PAPER SERIES\\nRETIREMENT AND THE ...   \n",
       "1        All rights reserved. Short sections of text,...   \n",
       "2       Thus, the evolution of pension structure can ...   \n",
       "3        DB pension wealth typically accumulates slow...   \n",
       "4        DC pensions accumulate a lump sum which depe...   \n",
       "...                                                  ...   \n",
       "17557  786***     (.063)  (.137)   (.071)   (.096)   ...   \n",
       "17558      Total  Mixed Sex  Same Sex  Boys Only   Gi...   \n",
       "17559  141)  N    2364  698   1666   940   726   ***p...   \n",
       "17560    Infant Mortality  -.892***   -.703***   -.51...   \n",
       "17561  Everyone Same Sex Mixed (Fraternal) Identical\\...   \n",
       "\n",
       "                                         processed_chunk  \\\n",
       "0      RETIREMENT AND THE EVOLUTION OF PENSION STRUCT...   \n",
       "1      All rights reserved. Short sections text, not ...   \n",
       "2      Thus, evolution pension structure can help exp...   \n",
       "3      DB pension wealth typically accumulates slowly...   \n",
       "4      DC pensions accumulate lump sum which depends ...   \n",
       "...                                                  ...   \n",
       "17557  786*** (.063) (.137) (.071) (.096) (.107) N 44...   \n",
       "17558  Total Mixed Sex Same Sex Boys Only Girls Only ...   \n",
       "17559  141) N 2364 698 1666 940 726 ***p<.001 **p<.01...   \n",
       "17560  Infant Mortality -.892*** -.703*** -.512*** (....   \n",
       "17561  Everyone Same Sex Mixed (Fraternal) Identical ...   \n",
       "\n",
       "                                               file_path  \\\n",
       "0      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "1      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "2      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "3      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "4      C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "...                                                  ...   \n",
       "17557  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "17558  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "17559  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "17560  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "17561  C:\\Users\\Steven\\Documents\\Python\\Data\\NBER pap...   \n",
       "\n",
       "                                                  vector  \n",
       "0      [0.9494798, -0.5101314, 1.260272, -3.4051301, ...  \n",
       "1      [-0.41856015, 0.94318783, -0.1712659, -3.14227...  \n",
       "2      [0.24726994, 1.506088, -0.993264, -2.7431295, ...  \n",
       "3      [1.8708433, 0.6725198, -2.1666236, -3.2994564,...  \n",
       "4      [1.0445604, 0.36211833, -0.17084824, -1.149713...  \n",
       "...                                                  ...  \n",
       "17557  [-0.0041005667, -1.6556355, 2.509584, -0.22076...  \n",
       "17558  [0.13459334, -1.6275283, 2.4162931, -0.3573123...  \n",
       "17559  [0.07510667, -1.8058623, 2.654449, 0.3212689, ...  \n",
       "17560  [-0.8045424, -2.0775964, 1.3887693, 0.8446741,...  \n",
       "17561  [-2.1238828, -2.2521822, 2.0788414, 0.9449485,...  \n",
       "\n",
       "[17562 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = model.encode(df['processed_chunk'])\n",
    "# This returns a np array of shape (n, d), where n is \n",
    "#     number of chunks and d is embedding dimensions.\n",
    "\n",
    "df['vector'] = [i for i in np.unstack(vecs)]\n",
    "# Add the embeddings to our dataframe in a single variable,\n",
    "#     so each cell contains the d-dimensional np vector.\n",
    "\n",
    "df\n",
    "# takes 3 seconds to encode 17562 chunks, 33 files per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'think', 'this', 'is', 'what', 'I', 'need', ';)', 'will'],\n",
       " ['I', 'need', ';)', 'will', 'see', 'if', 'it', 'works', 'and'],\n",
       " ['if', 'it', 'works', 'and', 'check', 'answer', 'if', 'it', 'does'],\n",
       " ['answer', 'if', 'it', 'does', 'for', 'my', 'problem,', 'I', 'might'],\n",
       " ['my', 'problem,', 'I', 'might', 'still', 'need', 'some', 'help,', 'thanks'],\n",
       " ['need', 'some', 'help,', 'thanks', 'everyone,', 'this', 'was', 'fast', ':D']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_chunker(_chunk_size=256, _chunk_overlap=64):\n",
    "    # Logic to adjust inputs if necessary\n",
    "    if 2 * _chunk_overlap > _chunk_size:\n",
    "        _chunk_overlap = round(_chunk_size / 2)\n",
    "        print(f\"Warning: chunk overlap too large, setting to {_chunk_overlap}.\")\n",
    "\n",
    "    def chunker(text):\n",
    "        # Split text into words\n",
    "        words = text.split(' ')\n",
    "        chunks = []\n",
    "\n",
    "        start = 0\n",
    "        end = _chunk_size-1\n",
    "\n",
    "        while end < len(words):\n",
    "            chunk = words[start:end]\n",
    "            chunks.append(chunk)\n",
    "\n",
    "            start = end - _chunk_overlap + 1\n",
    "            end = end + _chunk_overlap\n",
    "        \n",
    "        # make sure the last chunk has all the remaining words\n",
    "        if end < len(words) - 1:\n",
    "            chunks.append(words[end:])\n",
    "\n",
    "        return(chunks)\n",
    "\n",
    "    return(chunker)\n",
    "\n",
    "chunker = setup_chunker(10, 5)\n",
    "chunker(\"I think this is what I need ;) will see if it works and check answer if it does for my problem, I might still need some help, thanks everyone, this was fast :D \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 0, End: 14.\n",
      "Start: 10, End: 19.\n",
      "Start: 15, End: 24.\n",
      "Start: 20, End: 29.\n",
      "Start: 25, End: 34.\n",
      "Start: 30, End: 39.\n",
      "Start: 35, End: 44.\n",
      "Start: 40, End: 49.\n",
      "Start: 45, End: 54.\n",
      "Start: 50, End: 59.\n",
      "Start: 55, End: 64.\n",
      "Start: 60, End: 69.\n",
      "Start: 65, End: 74.\n",
      "Start: 70, End: 79.\n",
      "Start: 75, End: 84.\n",
      "Start: 80, End: 89.\n",
      "Start: 85, End: 94.\n",
      "Start: 90, End: 99.\n"
     ]
    }
   ],
   "source": [
    "chunk_size=15\n",
    "chunk_overlap=5\n",
    "\n",
    "start = 0\n",
    "end = chunk_size-1\n",
    "\n",
    "while end < 100:\n",
    "    print(f\"Start: {start}, End: {end}.\")\n",
    "    start = end - chunk_overlap + 1\n",
    "    end = end + chunk_overlap\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
